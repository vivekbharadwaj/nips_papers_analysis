{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What I want to do: ** Run the data download, import and processing scripts to get a copy of the nips papers from the past so as to recreate analysis for 2017\n",
    "\n",
    "This is a recreation of Ben Hamner's [github code](https://github.com/benhamner/nips-papers) to get data from nips papers, which he released as part of a kaggle kernel. The code is now present in the scripts directory. I'm simply running it block by block on jupyter to make sure it's all in order. We already have the papers from 1987 to 2016 in the [Kaggle Kernel](https://www.kaggle.com/benhamner/nips-papers/data). Let's simply append the 2017 papers and then create a new pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os, sys\n",
    "import pandas as pd; import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "from datetime import  datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url  = \"http://papers.nips.cc\"\n",
    "\n",
    "# index_urls = {1987: \"https://papers.nips.cc/book/neural-information-processing-systems-1987\"}\n",
    "index_urls={}\n",
    "for i in range(30, 31):\n",
    "    year = i+1987\n",
    "    index_urls[year] = \"http://papers.nips.cc/book/advances-in-neural-information-processing-systems-%d-%d\" % (i, year)\n",
    "\n",
    "nips_authors = set()\n",
    "papers = list()\n",
    "paper_authors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2017: 'http://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to get the text from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_from_pdf(pdf_path, temp_path):\n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "    subprocess.call([\"pdftotext\", pdf_path, temp_path])\n",
    "    f = open(temp_path, encoding=\"utf8\", errors='ignore')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    os.remove(temp_path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the subprocess call for \"pdftotext\". This is a command line open-source utility that does what it says on the name. I tried a couple of ways to install it on macbook, but the way that worked for me is from [this link](http://macappstore.org/pdftotext/) :\n",
    "\n",
    "- In the terminal app in your macbook: ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" < /dev/null 2> /dev/null ; brew install caskroom/cask/brew-cask 2> /dev/null\n",
    "- Then run: brew cask install pdftotext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute scrape and parse code to get nips 2017 papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE 1: ** If you already have beautiful soup installed, make sure you have the lxml parser installed too (conda install lxml)\n",
    "\n",
    "**NOTE 2: ** If you get unicode decode errors while parsing, use \"errors='ignore'\" in your pdftotext parsing function You'll just lose some characters. but if your don't care about them as they seem to be extra characters originating from a the bad formatting. Found the answer to this from [this SO answer](https://stackoverflow.com/questions/42339876/error-unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2017; 679 Papers Found; Time Elapsed: 0 mins\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/authors2008_to_2017.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-898b222b8957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mstrUntilYear_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2008_to_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mstrUntilYear_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2008_to_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnips_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/authors\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrUntilYear_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"event_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pdf_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"abstract\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"paper_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/papers\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrUntilYear_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_authors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"paper_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"author_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/paper_authors\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrUntilYear_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Vivek/anaconda/envs/vivpy34/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Vivek/anaconda/envs/vivpy34/lib/python3.4/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1458\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1459\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1461\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Vivek/anaconda/envs/vivpy34/lib/python3.4/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression, memory_map)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/authors2008_to_2017.csv'"
     ]
    }
   ],
   "source": [
    "startime = datetime.now()\n",
    "for year in sorted(index_urls.keys()):\n",
    "    index_url = index_urls[year]\n",
    "    index_html_path = os.path.join(\"working\", \"html\", str(year)+\".html\")\n",
    "\n",
    "    if not os.path.exists(index_html_path):\n",
    "        r = requests.get(index_url)\n",
    "        if not os.path.exists(os.path.dirname(index_html_path)):\n",
    "            os.makedirs(os.path.dirname(index_html_path))\n",
    "        with open(index_html_path, \"wb\") as index_html_file:\n",
    "            index_html_file.write(r.content)\n",
    "    with open(index_html_path, \"rb\") as f:\n",
    "        html_content = f.read()\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    paper_links = [link for link in soup.find_all('a') if link[\"href\"][:7]==\"/paper/\"]\n",
    "    print(\"Year: {}; {} Papers Found; Time Elapsed: {} mins\".format(year,len(paper_links),str(int((datetime.now()-startime).seconds/60))))\n",
    "\n",
    "\n",
    "    temp_path = os.path.join(\"working\", \"temp.txt\")\n",
    "\n",
    "    for link in paper_links:\n",
    "        paper_title = link.contents[0]\n",
    "        info_link = base_url + link[\"href\"]\n",
    "        pdf_link = info_link + \".pdf\"\n",
    "        pdf_name = link[\"href\"][7:] + \".pdf\"\n",
    "        pdf_path = os.path.join(\"working\", \"pdfs\", str(year), pdf_name)\n",
    "        paper_id = re.findall(r\"^(\\d+)-\", pdf_name)[0]\n",
    "#         print(year, \" \", paper_id) #paper_title.encode('ascii', 'namereplace'))\n",
    "        if not os.path.exists(pdf_path):\n",
    "            pdf = requests.get(pdf_link)\n",
    "            if not os.path.exists(os.path.dirname(pdf_path)):\n",
    "                os.makedirs(os.path.dirname(pdf_path))\n",
    "            pdf_file = open(pdf_path, \"wb\")\n",
    "            pdf_file.write(pdf.content)\n",
    "            pdf_file.close()\n",
    "\n",
    "        paper_info_html_path = os.path.join(\"working\", \"html\", str(year), str(paper_id)+\".html\")\n",
    "        if not os.path.exists(paper_info_html_path):\n",
    "            r = requests.get(info_link)\n",
    "            if not os.path.exists(os.path.dirname(paper_info_html_path)):\n",
    "                os.makedirs(os.path.dirname(paper_info_html_path))\n",
    "            with open(paper_info_html_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        with open(paper_info_html_path, \"rb\") as f:\n",
    "            html_content = f.read()\n",
    "        paper_soup = BeautifulSoup(html_content, \"lxml\")\n",
    "        try: \n",
    "            abstract = paper_soup.find('p', attrs={\"class\": \"abstract\"}).contents[0]\n",
    "        except:\n",
    "            print(\"Abstract not found %s\" % paper_title.encode(\"ascii\", \"replace\"))\n",
    "            print (\"For reference: \",year, \" \", paper_id)\n",
    "            abstract = \"\"\n",
    "        authors = [(re.findall(r\"-(\\d+)$\", author.contents[0][\"href\"])[0],\n",
    "                    author.contents[0].contents[0])\n",
    "                   for author in paper_soup.find_all('li', attrs={\"class\": \"author\"})]\n",
    "        for author in authors:\n",
    "            nips_authors.add(author)\n",
    "            paper_authors.append([len(paper_authors)+1, paper_id, author[0]])\n",
    "        event_types = [h.contents[0][23:] for h in paper_soup.find_all('h3') if h.contents[0][:22]==\"Conference Event Type:\"]\n",
    "        if len(event_types) != 1:\n",
    "            #print(event_types)\n",
    "            #print([h.contents for h in paper_soup.find_all('h3')].__str__().encode(\"ascii\", \"replace\"))\n",
    "            #raise Exception(\"Bad Event Data\")\n",
    "            event_type = \"\"\n",
    "        else:\n",
    "            event_type = event_types[0]\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            if f.read(15)==b\"<!DOCTYPE html>\":\n",
    "                print(\"PDF MISSING\")\n",
    "                continue\n",
    "        paper_text = text_from_pdf(pdf_path, temp_path)\n",
    "        papers.append([paper_id, year, paper_title, event_type, pdf_name, abstract, paper_text])\n",
    "        \n",
    "    strUntilYear_csv = \"2008_to_\"+str(year)+\".csv\"\n",
    "    strUntilYear_pickle = \"2008_to_\"+str(year)+\".pickle\"\n",
    "    pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_csv(\"output/authors\"+strUntilYear_csv, index=False)\n",
    "    pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_csv(\"output/papers\"+strUntilYear_csv, index=False)\n",
    "    pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_csv(\"output/paper_authors\"+strUntilYear_csv, index=False)\n",
    "    pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_pickle(\"output/authors\"+strUntilYear_pickle)\n",
    "    pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_pickle(\"output/papers\"+strUntilYear_pickle)\n",
    "    pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_pickle(\"output/paper_authors\"+strUntilYear_pickle)\n",
    "\n",
    "pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_csv(\"output/authors.csv\", index=False)\n",
    "pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_csv(\"output/papers.csv\", index=False)\n",
    "pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_csv(\"output/paper_authors.csv\", index=False)\n",
    "\n",
    "# also pickling for easy access\n",
    "print (\"Remember, these pickles will work only for the following Python version:\",sys.version)\n",
    "pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_pickle(\"output/authors.pickle\")\n",
    "pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_pickle(\"output/papers.pickle\")\n",
    "pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_pickle(\"output/paper_authors.pickle\")\n",
    "\n",
    "print(\"Total Time Elapsed: {} mins\".format(str(int((datetime.now()-startime).seconds/60))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_csv(\"output/authors.csv\", index=False)\n",
    "pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_csv(\"output/papers.csv\", index=False)\n",
    "pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_csv(\"output/paper_authors.csv\", index=False)\n",
    "\n",
    "# also pickling (to json object) for easy access\n",
    "# print (\"Remember, these pickles will work only for the following Python version:\",sys.version)\n",
    "pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_json(\"output/authors.json\")\n",
    "pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_json(\"output/papers.json\")\n",
    "pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_json(\"output/paper_authors.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I used json to parse these files. am beginning to like json format more and more over good ole' pickles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 1987-2016 from kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/benhamner/nips-papers/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess what needs to be done to merge 2017 with previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_auth = pd.read_csv('output/authors_until2017.csv')\n",
    "df_auth['id']=df_auth['id'].astype(int)\n",
    "df_auth = df_auth.sort_values('id',ascending=True)\n",
    "df_auth.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_auth2017 = pd.read_csv('output/authors_2017.csv')\n",
    "df_auth2017['id']=df_auth2017['id'].astype(int)\n",
    "df_auth2017 = df_auth2017.sort_values('id',ascending=True)\n",
    "df_auth2017.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9784, 1), (2036, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auth.shape, df_auth2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hisashi Suzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suguru Arimoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philip A. Chou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John C. Platt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alan H. Barr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ralph Linsker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene A. Tagliarini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Edward W. Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ken Hsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>David Brady</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name\n",
       "id                    \n",
       "1       Hisashi Suzuki\n",
       "2       Suguru Arimoto\n",
       "3       Philip A. Chou\n",
       "4        John C. Platt\n",
       "5         Alan H. Barr\n",
       "6        Ralph Linsker\n",
       "7   Gene A. Tagliarini\n",
       "8       Edward W. Page\n",
       "9              Ken Hsu\n",
       "10         David Brady"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auth.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Geoffrey E. Hinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Jian Wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Avrim Blum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Jonathan D. Cohen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name\n",
       "id                     \n",
       "121  Geoffrey E. Hinton\n",
       "150             Jian Wu\n",
       "178       Yoshua Bengio\n",
       "205          Avrim Blum\n",
       "347   Jonathan D. Cohen"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auth2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see just the first few rows of the two tables, its interesting to see an overlap between names and ids. The best way to check this is to concatenate the two table and then see whether the names all match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9787, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authCombined = pd.merge(left=df_auth,right=df_auth2017,how='outer',left_index=True,right_index=True)\n",
    "df_authCombined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_x</th>\n",
       "      <th>name_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Felix Yu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert S. Chen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10484</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Gray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name_x          name_y\n",
       "id                          \n",
       "8302     NaN        Felix Yu\n",
       "10483    NaN  Robert S. Chen\n",
       "10484    NaN      Scott Gray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authCombined[pd.isnull(df_authCombined.name_x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How interesting that out of the NIPS papers, there are only 3 authors who have published to NIPS for the first time. I'm too much of an outsider to comment on why this might be the case. Combining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_authCombined['name']=np.where(pd.isnull(df_authCombined.name_x),\n",
    "                                 df_authCombined['name_y'],df_authCombined['name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_authCombined.drop(['name_x','name_y'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hisashi Suzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suguru Arimoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philip A. Chou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John C. Platt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alan H. Barr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name\n",
       "id                \n",
       "1   Hisashi Suzuki\n",
       "2   Suguru Arimoto\n",
       "3   Philip A. Chou\n",
       "4    John C. Platt\n",
       "5     Alan H. Barr"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authCombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv and json\n",
    "df_authCombined.to_csv('output/authors.csv')\n",
    "df_authCombined.to_json('output/authors.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7241, 6), (679, 6))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = pd.read_csv('output/papers_until2017.csv')\n",
    "df_pa['id']=df_pa['id'].astype(int)\n",
    "df_pa = df_pa.sort_values('id',ascending=True)\n",
    "df_pa.set_index('id', inplace=True)\n",
    "df_pa2017 = pd.read_csv('output/papers_2017.csv')\n",
    "df_pa2017['id']=df_pa2017['id'].astype(int)\n",
    "df_pa2017 = df_pa2017.sort_values('id',ascending=True)\n",
    "df_pa2017.set_index('id', inplace=True)\n",
    "df_pa.shape, df_pa2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 12)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case, the best way to combine papers is to simply merge them\n",
    "df_paCombined = pd.merge(left=df_pa,right=df_pa2017,how='outer',left_index=True,right_index=True)\n",
    "df_paCombined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Looks like the papers have been updated in the old dataset to include 2017 papers. Let's confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paCombined[pd.isnull(df_paCombined.year_x)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so simply save old papers to csv and json\n",
    "df_pa.to_csv('output/papers.csv')\n",
    "df_pa.to_json('output/papers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x146a6e518>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHVCAYAAAD8YtYeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1476cbef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig = plt.figure(figsize=(16,8));ax = fig.add_subplot(111)\n",
    "df_pa.year.hist(bins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for paper authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20838, 2), (2494, 2))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it looks like for this table, the id is auto-incremented. so it's time to define your own id\n",
    "df_papauth = pd.read_csv('output/paper_authors_until2017.csv')\n",
    "df_papauth['paper_id']=df_papauth['paper_id'].astype(int).astype(str)\n",
    "df_papauth['author_id']=df_papauth['author_id'].astype(int).astype(str)\n",
    "df_papauth['id']=df_papauth['paper_id']+df_papauth['author_id']\n",
    "df_papauth = df_papauth.sort_values('id',ascending=True)\n",
    "df_papauth.set_index('id', inplace=True)\n",
    "df_papauth2017 = pd.read_csv('output/paper_authors_2017.csv')\n",
    "df_papauth2017['paper_id']=df_papauth2017['paper_id'].astype(int).astype(str)\n",
    "df_papauth2017['author_id']=df_papauth2017['author_id'].astype(int).astype(str)\n",
    "df_papauth2017['id']=df_papauth2017['paper_id']+df_papauth2017['author_id']\n",
    "df_papauth2017 = df_papauth2017.sort_values('id',ascending=True)\n",
    "df_papauth2017.set_index('id', inplace=True)\n",
    "df_papauth.shape, df_papauth2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20843, 4)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case, the best way to combine papers is to simply merge them\n",
    "df_papauthCombined = pd.merge(left=df_papauth,right=df_papauth2017,how='outer',left_index=True,right_index=True)\n",
    "df_papauthCombined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>paper_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001229</th>\n",
       "      <td>1000</td>\n",
       "      <td>1229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000902</th>\n",
       "      <td>1000</td>\n",
       "      <td>902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011230</th>\n",
       "      <td>1001</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001371</th>\n",
       "      <td>1001</td>\n",
       "      <td>371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100155</th>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id_x author_id_x paper_id_y author_id_y\n",
       "id                                                    \n",
       "10001229       1000        1229        NaN         NaN\n",
       "1000902        1000         902        NaN         NaN\n",
       "10011230       1001        1230        NaN         NaN\n",
       "1001371        1001         371        NaN         NaN\n",
       "100155          100         155        NaN         NaN"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_papauthCombined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's 5 new paper author combinations. So it must be a revision in the nips website since Ben has gone ahead and updated the info for 2017. I wish I had known this in advance coz the dataset reference didn't mention anything about it being updated for 2017. Additionally, the year information is present in the papers dataset which is not peek friendly. Moving on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_papauthCombined['paper_id']=np.where(pd.isnull(df_papauthCombined.paper_id_x),\n",
    "                                 df_papauthCombined['paper_id_y'],df_papauthCombined['paper_id_x'])\n",
    "df_papauthCombined['author_id']=np.where(pd.isnull(df_papauthCombined.author_id_x),\n",
    "                                 df_papauthCombined['author_id_y'],df_papauthCombined['author_id_x'])\n",
    "df_papauthCombined.drop(['paper_id_x','author_id_x','paper_id_y','author_id_y'],axis=1, inplace=True)\n",
    "df_papauthCombined = df_papauthCombined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv and json\n",
    "df_papauthCombined.to_csv('output/paper_authors.csv')\n",
    "df_papauthCombined.to_json('output/paper_authors.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:vivpy34]",
   "language": "python",
   "name": "conda-env-vivpy34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
